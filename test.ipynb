{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import loader\n",
    "import utils\n",
    "import preprocess_data\n",
    "from config import config_base\n",
    "from config import config_r_net\n",
    "from config import config_match_lstm\n",
    "from config import config_bi_daf\n",
    "from modules import match_lstm\n",
    "from modules import r_net\n",
    "from modules import bi_daf\n",
    "\n",
    "# config\n",
    "config = config_match_lstm.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load vocab\n",
    "lang = loader.load_vocab(config.vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_np = loader.load_w2v(config.embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.452 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "test_data = loader.load_data(config.test_df, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = loader.build_loader(\n",
    "        dataset=test_data[:2],\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "        'embedding': embedding_np,\n",
    "        'embedding_type': config.embedding_type,\n",
    "        'embedding_is_training': config.embedding_is_training,\n",
    "        'mode': config.mode,\n",
    "        'hidden_size': config.hidden_size,\n",
    "        'dropout_p': config.dropout_p,\n",
    "        'encoder_dropout_p': config.encoder_dropout_p,\n",
    "        'encoder_bidirectional': config.encoder_bidirectional,\n",
    "        'encoder_layer_num': config.encoder_layer_num,\n",
    "        'is_bn': config.is_bn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = eval(config.model_name).Model(param)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model,  model/match_lstm_1\n",
      "best_epoch: 9, best_step:24700, best_loss:1.6659, best_time:31607\n"
     ]
    }
   ],
   "source": [
    "    model_path = os.path.join('model', config.model_save)\n",
    "    print('load model, ', model_path)\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state['best_model_state'])\n",
    "\n",
    "    best_loss = state['best_loss']\n",
    "    best_epoch = state['best_epoch']\n",
    "    best_step = state['best_step']\n",
    "    time_use = state['time']\n",
    "    print('best_epoch:%2d, best_step:%5d, best_loss:%.4f, best_time:%d' % (best_epoch, best_step, best_loss, time_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    batch = batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = utils.deal_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 293])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_prop = outputs\n",
    "mask = utils.get_mask(batch[0])\n",
    "max_tokens = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = answer_search(answer_prop, mask, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24, 112,  37,   9,  47,  82, 105,  40,  50,  15,  83,  89,  66,\n",
       "        11, 136,  37,   4,  82,  53,  77,  27,  69,  44,  56, 152,  44,\n",
       "       108,  35,  93,  19,  69,  43])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = a.cpu().numpy()\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8570977e-01, 1.5757346e-03, 1.3563248e-04, ..., 1.0000000e-06,\n",
       "        1.0000000e-06, 1.0000000e-06],\n",
       "       [2.2726918e-03, 7.3753281e-06, 1.0440446e-04, ..., 1.0000000e-06,\n",
       "        1.0000000e-06, 1.0000000e-06],\n",
       "       [1.8052991e-06, 8.6687521e-07, 5.0409599e-06, ..., 1.0000000e-06,\n",
       "        1.0000000e-06, 1.0000000e-06],\n",
       "       ...,\n",
       "       [5.2722113e-04, 6.1415209e-05, 1.1539657e-04, ..., 1.0000000e-06,\n",
       "        1.0000000e-06, 1.0000000e-06],\n",
       "       [4.2834989e-07, 2.0494163e-07, 4.3651485e-06, ..., 1.0000000e-06,\n",
       "        1.0000000e-06, 1.0000000e-06],\n",
       "       [3.7689028e-07, 2.5841240e-07, 5.0667222e-08, ..., 1.0000000e-06,\n",
       "        1.0000000e-06, 1.0000000e-06]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_s_p.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  24,  112,   37,    9,   47,   82,  105,   40,   50,   15,\n",
       "           83,   89,   66,   11,  136,   37,    4,   82,   53,   77,\n",
       "           27,   69,   44,   56,  152,   44,  108,   35,   93,   19,\n",
       "           69,   43], device='cuda:0'),\n",
       " tensor([  29,  112,   38,   11,  195,   87,  105,   40,   53,   15,\n",
       "           86,   90,   70,   14,  176,   40,    8,   92,   54,  100,\n",
       "           30,   79,   45,   60,  171,   47,  110,   35,  106,   21,\n",
       "           79,   46], device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_search(answer_prop, mask, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans_s_p = answer_prop[0]\n",
    "ans_e_p = answer_prop[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_search(answer_prop, mask, max_tokens):\n",
    "    \"\"\"\n",
    "     global search best answer for model predict\n",
    "    :param answer_prop: (2, batch_size, c_len)\n",
    "    :param mask: (batch_size, c_len)\n",
    "    :param max_tokens: .\n",
    "    :return: ans_range, score\n",
    "    \"\"\"\n",
    "    batch_size = answer_prop.size(1)\n",
    "    c_len = answer_prop.size(2)\n",
    "\n",
    "    # get min length\n",
    "    lengths = mask.data.eq(1).long().sum(dim=1).squeeze()\n",
    "    min_length, _ = torch.min(lengths, 0)\n",
    "    min_length = min_length.item()\n",
    "\n",
    "    # max move steps\n",
    "    max_move = max_tokens + c_len - min_length\n",
    "    max_move = min(c_len, max_move)\n",
    "\n",
    "    ans_s_p = answer_prop[0]\n",
    "    ans_e_p = answer_prop[1]\n",
    "    b_zero = answer_prop.new_zeros(batch_size, 1)\n",
    "\n",
    "    ans_s_e_p_lst = []\n",
    "    for i in range(max_move):\n",
    "        temp_ans_s_e_p = ans_s_p * ans_e_p\n",
    "        ans_s_e_p_lst.append(temp_ans_s_e_p)\n",
    "\n",
    "        ans_s_p = ans_s_p[:, :(c_len - 1)]\n",
    "        ans_s_p = torch.cat([b_zero, ans_s_p], dim=1)\n",
    "\n",
    "    ans_s_e_p = torch.stack(ans_s_e_p_lst, dim=2)\n",
    "\n",
    "    # get the best end position, and move steps\n",
    "    max_prop1, max_prop_idx1 = torch.max(ans_s_e_p, 1)\n",
    "    max_prop2, max_prop_idx2 = torch.max(max_prop1, 1)\n",
    "\n",
    "    ans_e = max_prop_idx1.gather(1, max_prop_idx2.unsqueeze(1)).squeeze(1)\n",
    "    ans_s = ans_e - max_prop_idx2\n",
    "\n",
    "    return ans_s, ans_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
