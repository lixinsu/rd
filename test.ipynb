{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file, 'w') as file:\n",
    "    file.writelines('ss jk lio j' + '\\n')\n",
    "    file.writelines('ss df fds' + '\\n')\n",
    "    file.writelines('ss $$$ fds' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u3000'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'　'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-10 09:07:25,112 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-09-10 09:07:25,113 : INFO : collecting all words and their counts\n",
      "2018-09-10 09:07:25,113 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-10 09:07:25,114 : INFO : collected 7 word types from a corpus of 10 raw words and 3 sentences\n",
      "2018-09-10 09:07:25,114 : INFO : Loading a fresh vocabulary\n",
      "2018-09-10 09:07:25,114 : INFO : min_count=1 retains 7 unique words (100% of original 7, drops 0)\n",
      "2018-09-10 09:07:25,115 : INFO : min_count=1 leaves 10 word corpus (100% of original 10, drops 0)\n",
      "2018-09-10 09:07:25,115 : INFO : deleting the raw counts dictionary of 7 items\n",
      "2018-09-10 09:07:25,115 : INFO : sample=0.001 downsamples 7 most-common words\n",
      "2018-09-10 09:07:25,115 : INFO : downsampling leaves estimated 0 word corpus (8.8% of prior 10)\n",
      "2018-09-10 09:07:25,116 : INFO : estimated required memory for 7 words and 2 dimensions: 3612 bytes\n",
      "2018-09-10 09:07:25,116 : INFO : resetting layer weights\n",
      "2018-09-10 09:07:25,117 : INFO : training model with 3 workers on 7 vocabulary and 2 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-09-10 09:07:25,120 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-10 09:07:25,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-10 09:07:25,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-10 09:07:25,121 : INFO : EPOCH - 1 : training on 10 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-09-10 09:07:25,123 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-10 09:07:25,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-10 09:07:25,124 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-10 09:07:25,124 : INFO : EPOCH - 2 : training on 10 raw words (1 effective words) took 0.0s, 717 effective words/s\n",
      "2018-09-10 09:07:25,125 : INFO : training on a 20 raw words (1 effective words) took 0.0s, 135 effective words/s\n",
      "2018-09-10 09:07:25,125 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "data_file = 'data_gen/test'\n",
    "dim = 2\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.Word2Vec(\n",
    "    sentences=LineSentence(data_file),\n",
    "    size=dim,\n",
    "    min_count=1,\n",
    "    iter=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from jieba import posseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pair('今天天气', 'i'), pair('还是', 'c'), pair('不错', 'a'), pair('的', 'uj')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '今天天气还是不错的'\n",
    "posseg.lcut(s, HMM=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a , b = list(zip(*posseg.lcut(s, HMM=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Today', 'NN'), ('is', 'VBZ'), ('good', 'JJ'), ('.', '.')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Today is good.'\n",
    "s = nltk.word_tokenize(s)\n",
    "nltk.pos_tag(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Today', 'is', 'good', '.'], ['NN', 'VBZ', 'JJ', '.'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Today is good.'\n",
    "split_word_en(s, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word_en(s, have_tag=False):\n",
    "    \"\"\"\n",
    "    英文分词\n",
    "    :param s: str\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if have_tag is False:\n",
    "        s = nltk.word_tokenize(s)\n",
    "        return s\n",
    "    else:\n",
    "        s = nltk.word_tokenize(s)\n",
    "        _, tags = list(zip(*nltk.pos_tag(s)))\n",
    "        return s, list(tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
